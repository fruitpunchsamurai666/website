[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_EX/Hands-on_Ex1.html",
    "href": "Hands-on_EX/Hands-on_Ex1.html",
    "title": "Hands-on_Ex1",
    "section": "",
    "text": "Hands-on_Ex1"
  },
  {
    "objectID": "In-class_EX/In-class_Ex03.html",
    "href": "In-class_EX/In-class_Ex03.html",
    "title": "In-class-ex03",
    "section": "",
    "text": "test test test"
  },
  {
    "objectID": "In-class_EX/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_EX/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "load packages\n\n\npacman::p_load(plotly, gt, patchwork, ggstatsplot, tidyverse, ggside, parameters,rstatix,patchwork)\n\n\nload dataset\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nqq plot\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data, aes(sample=ENGLISH))+stat_qq()+stat_qq_line()\n\nsw_t <- exam_data %>% \n  shapiro_test(ENGLISH)%>% \n  gt()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line, this is a clear indication that the set of data is not normally distributed."
  },
  {
    "objectID": "In-class_EX/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_EX/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "load package\n\n\npacman::p_load(jsonlite,tidygraph, ggraph, visNetwork, tidyverse) \n\n\nread JSON file\n\n\nMC1 <- jsonlite::fromJSON(\"D:/MITB/ISSS608/fruitpunchsamurai666/project/MC1/data/MC1.json\")\n\n\nread nodes and edge dataframe from JSON\n\n\n#read the sub-dataframe from the json file, select and rearrange the columns needed\nMC1_nodes <- as_tibble(MC1$nodes) %>% select(id, type, country)\nMC1_edges <- as_tibble(MC1$links) %>% select(source, target, type, weight, key)"
  },
  {
    "objectID": "In-class_EX/In-class_Ex05/In-class_Ex05.html#part-2---network-visualization",
    "href": "In-class_EX/In-class_Ex05/In-class_Ex05.html#part-2---network-visualization",
    "title": "In-class Exercise 5",
    "section": "Part 2 - Network Visualization",
    "text": "Part 2 - Network Visualization\n\nload package\n\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\nread data\n\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\nWrangling time\n\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nWrangling attributes by grouping by source-target-day and then removing emails that are cc to senders or only has been sent once.\n\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  #ungroup() is a function in the dplyr package in R that removes grouping from a grouped data frame. When data is grouped, operations are applied to each group separately. ungroup() is used to reverse the grouping operation so that subsequent operations are applied to the entire data frame as a whole.\n  ungroup()\n\n\nbuild tidygraph data model and rearrange the rows by weight in descending order\n\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\nplot the graph without x and y axis using Fruchterman and Reingold layout\n\n\ng <- ggraph(GAStech_graph,layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\nworking with facet (edge as an example)\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\ninteractive network graph with visNetwork\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n#shades the nodes by assigning unique colour to each category in the group field.\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Visual Analytics and Applications",
    "section": "",
    "text": "Welcome to my ISSS608 Visual Analytics and Applications homepage.\nThis page contains all my coursework prepared for the SMU MITB course ISSS608 Visual Analytics and Applications - 2023 April Term."
  },
  {
    "objectID": "Take-home_EX/Take-home_EX02/Take-home_Ex2.html",
    "href": "Take-home_EX/Take-home_EX02/Take-home_Ex2.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "With reference to Mini-Challenge 2 of VAST Challenge 2023 and by using appropriate static and interactive statistical graphics methods, you are required to help FishEye identify companies that may be engaged in illegal fishing. (website: https://vast-challenge.github.io/2023/MC2.html)\nQuestion chosen: Use visual analytics to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns you find.\n\n\n\n\nload packages and read datasets\n\npacman::p_load(jsonlite,tidygraph, ggraph, visNetwork, tidyverse,igraph,  lubridate, clock,tidyverse, graphlayouts,plotly)\n\n\nMC2 <- jsonlite::fromJSON(\"D:/MITB/ISSS608/fruitpunchsamurai666/website/Take-home_EX/Take-home_EX02/data/mc2_challenge_graph.json\")\n\nread nodes and edge from JSON\n\n#read the sub-dataframe from the json file, select and rearrange the columns needed\nmc2_nodes <- as_tibble(MC2$nodes) %>%\n  select(id, shpcountry, rcvcountry)\nmc2_edges <- as_tibble(MC2$links) %>%\n  mutate(ArrivalDate = ymd(arrivaldate)) %>%\n  mutate(Year = year(ArrivalDate)) %>%\n  select(source, target, ArrivalDate, Year, hscode, valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd) %>% \n  distinct()\n\nWrangling attributes by grouping by source-target-year pair, and record the count as weight (only interested in those with count >100).\n\nThe HS code is composed of six digits, which provide information about the classification of goods. Research suggests that the first two digits of the hscode represent the chapter. The next two digits represent the heading. The following two digits indicate the subheading. In this exercise, I only keep rows with hscode starting with “30” or “16” which is custom Duty Of Fish and crustaceans/molluscs/other aquatic invertebrates and custom Duty Of preparation of meat/fish/crustaceans/molluscs/other aquatic invertebrates respectively. (Reference: https://www.cybex.in/indian-custom-duty/)\n\n    #filter out edges with first 2 characters of hscodes = 30 or 16, aggregate and keep count >100 ones\n    mc2_edges_aggregated <- mc2_edges %>%\n      filter(substr(hscode, 1, 2) == \"30\"|substr(hscode, 1, 2) == \"16\") %>%\n      group_by(source, target, Year) %>%\n        summarise(weights = n()) %>%\n      filter(source!=target) %>%\n      filter(weights > 100) %>%   #only keep those with count >100\n      ungroup()\n   \n    #update nodes list according to the updated edge list \n    id1 <- mc2_edges_aggregated %>%\n      select(source) %>%\n      rename(id = source)\n    id2 <- mc2_edges_aggregated %>%\n      select(target) %>%\n      rename(id = target)\n    mc2_nodes_extracted <- rbind(id1, id2) %>%\n      distinct()\n\nVisualize the distribution of hscode chapters to understand the proportions of fishing related transactions.\n\n\nShow Code\n  counts <- mc2_edges %>%\n        group_by(chapter=substr(hscode, 1, 2)) %>%\n        summarise(weights = n()) %>%\n        ungroup()\n  \n  total <- sum(counts$weights)\n  counts$percentage <- (counts$weights/ total) * 100\n  \n  highlight_chapter <- c(\"30\",\"16\")\n  \n  hscode_hist <- ggplot(data= counts, \n         aes(x= reorder(chapter,-percentage),y=percentage)) +\n    #geom_bar(stat = \"identity\",fill= '#6eba6a')   +\n    geom_bar(aes(fill = chapter %in% highlight_chapter), stat = \"identity\")+\n    geom_text(aes(label = ifelse(chapter %in% highlight_chapter, chapter, \"\")),\n              vjust = -0.5, color = \"black\", size = 3) +\n    labs(y= 'No. of records', x= 'chapter',\n         subtitle = \"Distribution of hscode\") +\n    scale_fill_manual(values = c(\"steelblue\", \"orange\"), guide = FALSE) +\n    theme(axis.title.y= element_text(angle=0), axis.text.x = element_blank(),\n          panel.background= element_blank(), axis.line= element_line(color= 'dimgrey'),\n          plot.subtitle = element_text(color = \"dimgrey\", size = 12, face = \"bold\", hjust=0.5))\n  hscode_hist\n\n\n\n\n\n\nBuild network graph dataframe.\n\n\n    mc2_graph <- tbl_graph(nodes = mc2_nodes_extracted,\n                           edges = mc2_edges_aggregated,\n                           directed = TRUE)\n\n\nHave a quick view of the network.\n\n\n\nShow Code\n      ggraph(mc2_graph,\n           layout = \"fr\") +\n      geom_edge_link(arrow = arrow(length = unit(2, 'mm'))) +\n      geom_node_point(aes()) +\n      theme_graph()\n\n\n\n\n\n\nThe plot above is too dense. Now let us view the network by year.\n\n\n\nShow Code\n    set_graph_style()\n    \n    g <- ggraph(mc2_graph, \n                layout = \"nicely\") + \n      geom_edge_link(aes(width=weights), \n                     alpha=0.2,arrow = arrow(length = unit(3, 'mm'))) +\n      scale_edge_width(range = c(0.1, 5)) +\n      geom_node_point( aes(),\n                      size = 1)\n    \n    g + facet_edges(~Year) +\n      th_foreground(foreground = \"grey80\",  \n                    border = TRUE) +\n      theme(legend.position = 'bottom')\n\n\n\n\n\n\nIt is still hard to visualize difference of the network plot by year. To be able to further zoom into the network, I decided to use the interactive visNetwork tool to better visualize it.\n\nFirstly create a function that can filter out edges from a specific year with trading records > 100 (similar to the previous step).\n\n\nShow Code\n  mc2_subset <- function(mc2_edges,year) {\n    mc2_edges_aggregated <- mc2_edges %>%\n    filter(Year == year) %>%\n    filter(substr(hscode, 1, 2) == \"30\"|substr(hscode, 1, 2) == \"16\") %>%\n    group_by(source, target, Year) %>%\n      summarise(weights = n()) %>%\n    filter(source!=target) %>%\n    filter(weights > 100) %>%\n    ungroup()\n    \n    #change column names for visnetwork usage later\n    colnames(mc2_edges_aggregated) <- c(\"from\", \"to\", \"Year\", \"weights\") \n    return(mc2_edges_aggregated)\n  }\n\n\nThen create another function that can update the unique nodes according to the edges subset by year (similar to the previous step).\n\n\nShow Code\n  update_nodes <- function(mc2_edges_aggregated) { \n    id1 <- mc2_edges_aggregated %>%\n     select(from) %>%\n     rename(id = from)\n    id2 <- mc2_edges_aggregated %>%\n     select(to) %>%\n      rename(id = to)\n    mc2_nodes_extracted <- rbind(id1, id2) %>%\n      distinct()\n    return(mc2_nodes_extracted)\n  }\n\n\nPass the filtered edge data into the function to generate a subset for each year, then generate the node list for that year accordingly as well.\n\n\nShow Code\n  edges_2028 <- mc2_subset(mc2_edges,2028)\n  nodes_2028 <- update_nodes(edges_2028)\n  \n  edges_2029 <- mc2_subset(mc2_edges,2029)\n  nodes_2029 <- update_nodes(edges_2029)\n  \n  edges_2030 <- mc2_subset(mc2_edges,2030)\n  nodes_2030 <- update_nodes(edges_2030)\n  \n  edges_2031 <- mc2_subset(mc2_edges,2031)\n  nodes_2031 <- update_nodes(edges_2031)\n  \n  edges_2032 <- mc2_subset(mc2_edges,2032)\n  nodes_2032 <- update_nodes(edges_2032)\n  \n  edges_2033 <- mc2_subset(mc2_edges,2033)\n  nodes_2033 <- update_nodes(edges_2033)\n  \n  edges_2034 <- mc2_subset(mc2_edges,2034)\n  nodes_2034 <- update_nodes(edges_2034)\n\n\n\n\n\nI use “louvain_partition” to detect the communities within the subset of each year, and observe how they evolve over time. (One limitation is that multi-level community detection works for undirected graphs only, so in this section mc2_graph directed is set to false).\n\n\nShow Code\n#return top 5 nodes with the highest degree for big communities (with nodes > 10)\ntop_5  <- function(nodes,edges) { \n  mc2_graph <- tbl_graph(nodes = nodes,\n                         edges = edges,\n                         directed = FALSE)\n  set.seed(123)\n  # run louvain with edge weights \n  louvain_partition <- igraph::cluster_louvain(mc2_graph, weights = E(mc2_graph)$weights) \n  \n  # assign communities to graph \n  mc2_graph$community <- louvain_partition$membership \n  \n  top_five <- data.frame() \n  for (i in unique(mc2_graph$community)) { \n    \n    # create subgraph for each community \n    subgraph <- induced_subgraph(mc2_graph, v = which(mc2_graph$community == i)) \n    \n    # for larger communities \n    if (igraph::gorder(subgraph) > 10) {  # only interested in big communities with nodes >10\n      # get degree \n      degree <- igraph::degree(subgraph) \n      \n      # get top five degrees \n     top_indices <- head(order(degree, decreasing = TRUE), 5)\n     top <- V(subgraph)$id[top_indices]\n    result <- data.frame(community = rep(i, length(top)), rank = 1:5, character = top) \n    } else { \n      result <- data.frame(community = NULL, rank = NULL, character = NULL) \n    } \n    \n    top_five <- top_five %>% \n      dplyr::bind_rows(result) \n  } \n  return(top_five)\n}\n\n\nFor big communities (with nodes > 10), return companies with top 5 highest degree centrality to investigate the changes over the year.\n\n\nShow Code\ntop2028 <- top_5(nodes_2028,edges_2028)\ntop2029 <- top_5(nodes_2029,edges_2029)\ntop2030 <- top_5(nodes_2030,edges_2030)\ntop2031 <- top_5(nodes_2031,edges_2031)\ntop2032 <- top_5(nodes_2032,edges_2032)\ntop2033 <- top_5(nodes_2033,edges_2033)\ntop2034 <- top_5(nodes_2034,edges_2034)\n\nknitr::kable(\ntop2028 %>% \n  tidyr::pivot_wider(names_from = rank, values_from = character),\n  caption = \"2028 - companies with top 5 degree centrality in big communities\"\n)\n\n\n\n2028 - companies with top 5 degree centrality in big communities\n\n\n\n\n\n\n\n\n\n\ncommunity\n1\n2\n3\n4\n5\n\n\n\n\n1\nCaracola del Sol Services\nPao gan SE Seal\nGreek Octopus SRL Logistics\nManipur Market Corporation Cargo\nNáutica del Mar Barracuda\n\n\n5\nhǎi dǎn Corporation Wharf\nMar de la Costa Company\nGoa Seaside Sp Overseas\nMarine Mermaids Incorporated Services\nNagaland Sea OJSC United\n\n\n11\nMar del Este CJSC\nDanish Plaice Swordfish AB Shipping\nAssam Market GmbH & Co. KG Dockyard\nCape of Good Hope Corporation\nDiao yu BV Logistics\n\n\n21\nMar de la Felicidad Corporation\nPunjab s Marine conservation\nbǐ mù yú Sagl Distribution\nYu xian SRL Industrial\nPao gan LC Freight\n\n\n\n\n\nShow Code\nknitr::kable(\ntop2029 %>% \n  tidyr::pivot_wider(names_from = rank, values_from = character),\n  caption = \"2029 - companies with top 5 degree centrality in big communities\"\n)\n\n\n\n2029 - companies with top 5 degree centrality in big communities\n\n\n\n\n\n\n\n\n\n\ncommunity\n1\n2\n3\n4\n5\n\n\n\n\n10\nhǎi dǎn Corporation Wharf\nMadhya Pradesh Market LLC\nMarine Mermaids Incorporated Services\nSea Star LLC Shipping\nRift Valley fishery Inc\n\n\n13\nSelous Game Reserve S.A. de C.V.\nChuan gou N.V. Delivery\nNeptune’s Harvest A/S Hijiki\nLake Tanganyika Inc Jetty\nPregolya S.A. de C.V. Import\n\n\n19\nUttarakhand Market Limited Liability Company Nautical\nNáutica del Sol Brothers\nSeaside Summit SE Merchants\nVolga River LLC Enterprises\nEstrella de la Costa SRL\n\n\n\n\n\nShow Code\nknitr::kable(\ntop2030 %>% \n  tidyr::pivot_wider(names_from = rank, values_from = character),\n  caption = \"2030 - companies with top 5 degree centrality in big communities\" \n)\n\n\n\n2030 - companies with top 5 degree centrality in big communities\n\n\n\n\n\n\n\n\n\n\ncommunity\n1\n2\n3\n4\n5\n\n\n\n\n2\nMar del Este CJSC\nSea Breeze Corporation Marine sanctuary\nChuan gou N.V. Delivery\nOlas del Mar N.V.\nWave Watchers Ltd. Liability Co\n\n\n5\nCosta de la Felicidad Shipping\nBaltic Catch SE Solutions\nBlue Horizon Family &\nMar del Paraíso Corporation Logistics\nMadagascar Coast AG Freight\n\n\n8\nYu gan Sea spray GmbH Industrial\nArena del Sol SRL\nAssam Market GmbH & Co. KG Dockyard\nCape of Good Hope Corporation\nDavid Limited Liability Company Worldwide\n\n\n14\nCaracola del Sol Services\nKong zhong diao yu Ges.m.b.H.\nSea Breezes S.A. de C.V. Freight\nNáutica del Mar Barracuda\nOcéano de Coral Corporation Marine conservation\n\n\n\n\n\nShow Code\nknitr::kable(\ntop2031 %>% \n  tidyr::pivot_wider(names_from = rank, values_from = character) ,\n  caption = \"2031 - companies with top 5 degree centrality in big communities\"\n)\n\n\n\n2031 - companies with top 5 degree centrality in big communities\n\n\n\n\n\n\n\n\n\n\ncommunity\n1\n2\n3\n4\n5\n\n\n\n\n5\nMar del Este CJSC\nChuan gou N.V. Delivery\nWave Watchers Ltd. Liability Co\nSea Breeze Corporation Marine sanctuary\nAqua Aura Nori Ltd. Corporation Brothers\n\n\n13\nCaracola del Sol Services\nSea Breezes S.A. de C.V. Freight\nKong zhong diao yu Ges.m.b.H.\nCosta de Oro BV\nCosta de Oro CJSC\n\n\n\n\n\nShow Code\nknitr::kable(\ntop2032 %>% \n  tidyr::pivot_wider(names_from = rank, values_from = character) ,\n  caption = \"2032 - companies with top 5 degree centrality in big communities\"\n)\n\n\n\n2032 - companies with top 5 degree centrality in big communities\n\n\n\n\n\n\n\n\n\n\ncommunity\n1\n2\n3\n4\n5\n\n\n\n\n1\nCaracola del Sol Services\nSea Breezes S.A. de C.V. Freight\nPao gan SE Seal\nPlaya de Arena OJSC Express\nCaracola del Este Ltd. Liability Co\n\n\n5\nMar del Este CJSC\nAqua Aura Nori Ltd. Corporation Brothers\nChuan gou N.V. Delivery\nCosta de Coral SRL United\nDanish Plaice Swordfish AB Shipping\n\n\n10\nCosta de la Felicidad Shipping\nBlue Horizon Family &\nDaniel Ferry N.V. Transit\nMadagascar Coast AG Freight\nBarco de Plata CJSC\n\n\n\n\n\nShow Code\nknitr::kable(\ntop2033 %>% \n  tidyr::pivot_wider(names_from = rank, values_from = character) ,\n  caption = \"2033 - companies with top 5 degree centrality in big communities\"\n)\n\n\n\n2033 - companies with top 5 degree centrality in big communities\n\n\n\n\n\n\n\n\n\n\ncommunity\n1\n2\n3\n4\n5\n\n\n\n\n2\nCaracola del Sol Services\nPlaya de Arena OJSC Express\nPao gan LC Freight\nSpanish Shrimp A/S Marine\nCaracola del Este Ltd. Liability Co\n\n\n8\nMar del Este CJSC\nBlue Horizon Family &\nLake Tana & Son’s\nCosta de la Felicidad Shipping\nMadagascar Coast AG Freight\n\n\n11\nKong zhong diao yu Ges.m.b.H.\nAquaDelight N.V. Coral Reef\nEstrella de la Costa SRL\nDutch Eel AB Holdings\nMarit GmbH & Co. KG\n\n\n13\nPao gan SE Seal\nKilimajaro Slopes Incorporated and Son’s\nSea Breezes S.A. de C.V. Freight\nnián yú Ltd. Corporation\nArena del Mar Marine Marine biology\n\n\n\n\n\nShow Code\nknitr::kable(\ntop2034 %>% \n  tidyr::pivot_wider(names_from = rank, values_from = character) ,\n  caption = \"2034 - companies with top 5 degree centrality in big communities\"\n)\n\n\n\n2034 - companies with top 5 degree centrality in big communities\n\n\n\n\n\n\n\n\n\n\ncommunity\n1\n2\n3\n4\n5\n\n\n\n\n2\nBelgian Cod BV Solutions\nDavid Limited Liability Company Worldwide\nAngeline Sea NV Worldwide\nBlue Horizon Inc Transport\nCape of Good Hope Corporation\n\n\n4\nhǎi dǎn Corporation Wharf\nAqua Aura SE Marine life\nBalkan Cat ОАО Transport\nGambia River Ges.m.b.H. &\nLLC S.A. de C.V.\n\n\n7\nMar del Este CJSC\nNeptune’s Harvest A/S Hijiki\nEstrella de la Costa AB Express\nSeaside Summit SE Merchants\nBelgian Scallop Harbor ОАО Freight\n\n\n9\nAquaDelight N.V. Coral Reef\nMadagascar Coast AG Freight\nEstrella de la Costa SRL\nLake Tana & Son’s\nEstrella del Mar Tilapia Oyj Marine\n\n\n10\nOlas del Sur Ltd\nUttarakhand Tidepool Oyj International\nCape Verde Islands Sp Transportation\nManipur Market Ltd. Liability Co\nManipur Market Ltd. Liability Co Transport\n\n\n14\nPao gan SE Seal\nnián yú Ltd. Corporation\nArena del Mar Marine Marine biology\nNiger Bend Limited Liability Company Marine ecology\nKilimajaro Slopes Incorporated and Son’s\n\n\n\n\n\nFrom the table we can see that “Sea Breezes S.A. de C.V. Freight” company became one of the companies with highest degree since 2030 and its degree centrality remains high for a few years. This could be a possible sign of illegal fishing.\nFrom the names of the company, we can see that there are some companies seem to have same origin and have their business extended in several different big communities. This might suggest some black market activities. For example:\n\nPao gan LC Freight & Pao gan SE Seal (community 2 and 13 in year 2033)\nEstrella de la Costa AB Express & Estrella de la Costa SRL & Estrella del Mar Tilapia Oyj Marine (community 7 and 9 in year 2034)\n\n\n\n\nPlot interactive visNetwork for each year, color the nodes by the community (group) detected. Node size indicates the betweenness centrality value. Edge width indicates the number of transactions between the two nodes.\n\n\nShow Code\nplot <- function(nodess,edgess,years){\nmc2_graph <- tbl_graph(nodes = nodess,\n                       edges = edgess,\n                       directed = FALSE)\nset.seed(123)\n# run louvain with edge weights \nlouvain_partition <- igraph::cluster_louvain(mc2_graph, weights = E(mc2_graph)$weights) \n\n# Calculate and assign the betweenness centrality values to the node attributes\nV(mc2_graph)$betweenness <- betweenness(mc2_graph)\n\nmc2_graph <- toVisNetworkData(mc2_graph)\nmc2_graph$edges$value <- mc2_graph$edges$weight\nmc2_graph$nodes$value <- mc2_graph$nodes$betweenness\n\n# assign communities to graph \nmc2_graph$nodes$community <- louvain_partition$membership \nmc2_graph$nodes$group <- louvain_partition$membership \n\n#copy the nodes id into label attribute\nmc2_graph$nodes$label <- paste0(as.character(nodess$id), \" (\", round(mc2_graph$nodes$value), \")\")\n\n#plot visnetwork graph\nvisNetwork(mc2_graph$nodes,mc2_graph$edges,main = as.character(years)) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,nodesIdSelection = TRUE,selectedBy = \"community\") %>%\n  visLayout(randomSeed = 123) \n}\n\nplot(nodes_2028,edges_2028,2028)\n\n\n\n\n\n\nShow Code\nplot(nodes_2029,edges_2029,2029)\n\n\n\n\n\n\nShow Code\nplot(nodes_2030,edges_2030,2030)\n\n\n\n\n\n\nShow Code\nplot(nodes_2031,edges_2031,2031)\n\n\n\n\n\n\nShow Code\nplot(nodes_2032,edges_2032,2032)\n\n\n\n\n\n\nShow Code\nplot(nodes_2033,edges_2033,2033)\n\n\n\n\n\n\nShow Code\nplot(nodes_2034,edges_2034,2034)\n\n\n\n\n\n\nBy investigating the networks above, below are some suspicious companies involved in IUU fishing identified.\n\nnian yu Ltd Corporation\n\nNian yu Ltd Corporation is suspicious as a source company because it always picks a neighbour to heavily trade with every year, such as Costa de la Felicidad Shipping (2028-2029) and Niger Bend Limited Liability Company Marine ecology (2030-2032). The number of transactions is much higher than others. In 2033 and 2034, it forms a small tightly connected network with a few other companies (i.e. heavy transactions between each other within the small network).This pattern might indicate unauthorized over fishing and transshipment/port avoidance activities.\n\nNiger Bend Limited Liability Company Marine ecology\n\nThis company starts to appear in the network from 2030 due to its sudden increase in transactions with nian yu. As explained in #1, the sudden jump in transactions with nian yu might suggest that it is involved in the same illegal transshipment or black market activities. It is also suspicious that a new company can start build up a tight relationship in such a short time. Then from 2032, it started to trade with other community central nodes as well as a target company. The company might be an old company caught fishing illegally and start up again under a different name. Below is a line plot showing how its betweenness centrality change over time.\n\n\nShow Code\n#create the graph object for each year\nbtw_trend <- function(company_name){\n\n  mc2_2028 <- tbl_graph(nodes = nodes_2028,\n                             edges = edges_2028,\n                             directed = FALSE)\n  \n  mc2_2029 <- tbl_graph(nodes = nodes_2029,\n                             edges = edges_2029,\n                             directed = FALSE)\n  \n  mc2_2030 <- tbl_graph(nodes = nodes_2030,\n                             edges = edges_2030,\n                             directed = FALSE)\n  \n  mc2_2031 <- tbl_graph(nodes = nodes_2031,\n                             edges = edges_2031,\n                             directed = FALSE)\n  \n  mc2_2032 <- tbl_graph(nodes = nodes_2032,\n                             edges = edges_2032,\n                             directed = FALSE)\n  \n  mc2_2033 <- tbl_graph(nodes = nodes_2033,\n                             edges = edges_2033,\n                             directed = FALSE)\n  \n  mc2_2034 <- tbl_graph(nodes = nodes_2034,\n                             edges = edges_2034,\n                             directed = FALSE)\n  \n  # Choose a specific node to calculate betweenness centrality\n  node_of_interest1 <- which(V(mc2_2028)$id == company_name)\n  node_of_interest2 <- which(V(mc2_2029)$id == company_name)\n  node_of_interest3 <- which(V(mc2_2030)$id == company_name)\n  node_of_interest4 <- which(V(mc2_2031)$id == company_name)\n  node_of_interest5 <- which(V(mc2_2032)$id == company_name)\n  node_of_interest6 <- which(V(mc2_2033)$id == company_name)\n  node_of_interest7 <- which(V(mc2_2034)$id == company_name)\n  \n  \n  # Calculate betweenness centrality for each time period\n  betweenness_year1 <- ifelse(is.null(betweenness(mc2_2028, v = node_of_interest1)),0,betweenness(mc2_2028, v = node_of_interest1))\n  betweenness_year2 <- ifelse(is.null(betweenness(mc2_2029, v = node_of_interest2)),0,betweenness(mc2_2029, v = node_of_interest2))\n  betweenness_year3 <- ifelse(is.null(betweenness(mc2_2030, v = node_of_interest3)),0,betweenness(mc2_2030, v = node_of_interest3))\n  betweenness_year4 <- ifelse(is.null(betweenness(mc2_2031, v = node_of_interest4)),0,betweenness(mc2_2031, v = node_of_interest4))\n  betweenness_year5 <- ifelse(is.null(betweenness(mc2_2032, v = node_of_interest5)),0,betweenness(mc2_2032, v = node_of_interest5))\n  betweenness_year6 <- ifelse(is.null(betweenness(mc2_2033, v = node_of_interest6)),0,betweenness(mc2_2033, v = node_of_interest6))\n  betweenness_year7 <- ifelse(is.null(betweenness(mc2_2034, v = node_of_interest7)),0,betweenness(mc2_2034, v = node_of_interest7))\n  \n  # Store the betweenness centrality values in a data structure\n  betweenness_values <- data.frame(Year = c(\"2028\", \"2029\", \"2030\", \"2031\", \"2032\", \"2033\", \"2034\"), \n                                   Betweenness = c(betweenness_year1, betweenness_year2, betweenness_year3, betweenness_year4, \n                                                   betweenness_year5, betweenness_year6, betweenness_year7))\n  #plot betweenness over the year\n  plot_ly(betweenness_values, x = ~Year, y = ~Betweenness, type = \"scatter\", mode = \"lines+markers\") %>%\n    layout(xaxis = list(title = \"Year\",type = \"category\", tickmode = \"linear\"), yaxis = list(title = \"Betweenness Centrality\"), \n           title = \"Betweenness Centrality of Node over Time\", width = 500, height = 300)\n  }\n\n\nbtw_trend(\"Niger Bend   Limited Liability Company Marine ecology\")\n\n\n\n\n\n\n\nSea breeze S.A.de C.V.Freight\n\nBefore 2030, it only has two neighbours(Costa de la Felicidad shipping and Caracola Sol services). While in 2030, it suddenly expanded its business, both betweenness and degree centrality increased. It became the linkage node of several communities by trading with the central node of each community, such as “Mar del Este CJSC”. (betweenness was > 1500 in 2030) Betweenness centrality measures the extent to which a node lies on the shortest paths between other nodes. The high node betweenness centrality might suggest the company plays a critical role in facilitating illegal activities, such as acting as intermediaries or brokers in the fish trade.\n\n\nShow Code\nbtw_trend(\"Sea Breezes S.A. de C.V. Freight \")\n\n\n\n\n\n\n\nSaltwater Sanctuary OAO Merchants\n\nThe company was having high betweenness in 2029 as it the only major connection point of 3 big communities. However the company was no longer shown up in the network plot after 2029, highly likely it was caught and forced to shut down due to illegal fishing."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex1.html",
    "href": "Take-home_EX/Take-home_Ex1.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "In this take-home exercise, you are required to apply the concepts and methods you had learned in Lesson 1-4 to reveal the demographic and financial characteristics of the city of Engagement by using appropriate static and interactive statistical graphics methods. This exercise requires a user-friendly and interactive solution that helps city managers and planners to explore the complex data in an engaging way and reveal hidden patterns.\n\n\n\n\n\n\npacman::p_load(patchwork, tidyverse, ggstatsplot, ggdist, gganimate, png, gt,plotly, ggstatsplot, ggside, parameters,rstatix,reshape2, gridExtra,ggpmisc,ggscatterstats,ggplot2,ungeviz,treemap,ggridges, viridis)\n\n\n    fin_data <- read_csv(\"data/FinancialJournal.csv\")\n    part_data <- read_csv(\"data/Participants.csv\")\n\n\n\n\n\nchange data types\n\n#change participantId to characters\nfin_data$participantId <- as.character(fin_data$participantId)\npart_data$participantId <- as.character(part_data$participantId)\n\n#change education level to ordinal\npart_data$educationLevel <- factor(part_data$educationLevel, ordered=TRUE, levels=c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\",\"Graduate\"))\n\nchange the format of timestamp\n\n#save the datetime into date and month 2 formats\nfin_data$timestamp <- format(as.Date(fin_data$timestamp), \"%Y-%m-%d\")\nfin_data$year_mth <- format(as.Date(fin_data$timestamp), \"%Y-%m\")\n\ncreate a new table by converting financial journal to wide format (participantId as rows and categories as columns)\n\n# Convert financial journal to wide format\nwide_fin <- pivot_wider(fin_data, id_cols = participantId, names_from = category, values_from = amount, values_fn = sum)\n\n# fill in NA with 0s (i.e. no transaction) in the resultant table\nwide_fin[is.na(wide_fin)] <- 0\n\njoin the wide format financial journal table with the participant table by participantId\n\nmerged_df <- merge(part_data, wide_fin, by = 'participantId')\n\ncalculate total income, total expenses and final balance (sum of all categories) for each participant\n\nmerged_df$expenses <- rowSums(merged_df[, c(\"Education\", \"Food\", \"Recreation\",\"Shelter\")])\nmerged_df$income <- rowSums(merged_df[, c(\"RentAdjustment\",\"Wage\")])\nmerged_df$balance <- rowSums(merged_df[, c(\"Education\", \"Food\", \"Recreation\",\"RentAdjustment\",\"Shelter\",\"Wage\")])\n\nNormality check and qq plot\n\n\nJoviality qq plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nqq <- ggplot(merged_df, aes(sample=joviality))+stat_qq()+stat_qq_line()\n\nsw_t <- merged_df%>% \n  shapiro_test(joviality)%>% \n  gt()\n\n\n\n\n\nFinancial summary qq plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nqq <- ggplot(merged_df, aes(sample=balance))+stat_qq()+stat_qq_line()\n\nsw_t <- merged_df%>% \n  shapiro_test(balance)%>% \n  gt()\n\n\n\n\nWe can see that the points from both joviality and financial balance deviate significantly from the straight diagonal line, this is a clear indication that they are not normally distributed.\n\nOutlier removal and histogram\nThis step is to remove “expenses” and “income” outliers. (to retain more data, I adjusted the 75%(Q3)/25%(Q1) quantile to 90%/10% quantile in the outlier formula respectively.\n\n# Calculating the upper limit and Interquartile range for \"expenses\" and \"income\"\n\nIQR_income = IQR(merged_df$income)\nIQR_exp = IQR(merged_df$expenses)\n\nincome_upper = quantile(merged_df$income,probs = 0.9)+1.5*IQR_income\nexp_lower = quantile(merged_df$expenses,probs = 0.1)-1.5*IQR_exp\n\n\n# Filtering out the outliers (too high income or expenses)\nmerged <-  merged_df %>%\n           filter ((income <= income_upper) &\n          (expenses >= exp_lower))\n\n\n\n\nShow Code\n#income histogram after outlier removal\nmean_income = mean(merged$income)\nstd_income = sd(merged$income)\n\nincome_hist <- ggplot(merged, aes(income))+\n  geom_histogram(aes(y=..density..), fill = '#133337', color = '#eeeeee')+\n  stat_function(fun = dnorm, args = list(mean = mean_income, sd = std_income), col=\"#66cccc\", size = .7)+\n   xlim(0, 200000)+\n  \n  labs(title = 'Income histogram after outlier removal', \n       x = \"total income\")+\n  \n  theme_minimal()+\n  \n  theme(plot.title = element_text(hjust = 0.1, size = 10, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        plot.caption = element_text(face = \"italic\", size = 10),\n        panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_line(linewidth = 0.25, linetype = 'dashed', colour = '#bebebe'),\n        axis.text.x = element_text(face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5,face = \"bold\"))\n\n#expenses histogram after outlier removal\nmean_exp = mean(merged$expenses)\nstd_exp = sd(merged$expenses)\n\nexpenses_hist <- ggplot(merged, aes(expenses))+\n  geom_histogram(aes(y=..density..), fill = '#133337', color = '#eeeeee')+\n  stat_function(fun = dnorm, args = list(mean = mean_exp, sd = std_exp), col=\"#66cccc\", size = .7)+\n   xlim(-35000, 0)+\n  labs(title = 'Expenses histogram after outlier removal', \n       x = \"total expenses\")+\n  \n  theme_minimal()+\n  \n  theme(plot.title = element_text(hjust = 0.1, size = 10, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        plot.caption = element_text(face = \"italic\", size = 10),\n        panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_line(linewidth = 0.25, linetype = 'dashed', colour = '#bebebe'),\n        axis.text.x = element_text(face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5,face = \"bold\"))\n\nincome_hist + expenses_hist\n\n\n\n\n\n\n\n\n\n\n\nFrom this line plot, we observe:\n\nHouseholdsize 3 has the highest total income (wage+rental adjustment).\nTotal expenses (absolute value) increases as household size increases, which is expected.\nHouseholdsize 1 has the most balance (total income - expenses).\n\n\n\nShow Code\n#add a column to store absolute value of total expense\nmerged$expenses_abs <- abs(merged$expenses)\n\n#filter income, expenses and balance columns and change to long format\nmerged_long <- merged %>% \n  select(householdSize,income,expenses_abs,balance) %>% \n  group_by(householdSize)%>% \n   summarise(avg_income = mean(income),\n              avg_expenses = mean(expenses_abs),\n              avg_balance = mean(balance)) %>%\n  pivot_longer(cols = c(\"avg_income\", \"avg_expenses\", \"avg_balance\"), names_to = \"type\", values_to = \"amount\") %>% \n  ungroup() \n\n#line plot \nline_p1 <-merged_long %>%\n  ggplot(aes(x = householdSize, y = amount, colour = type))+\n  geom_smooth(alpha = 0.1) +\n  theme_classic() +\n  labs(title = \"Total income, expenses and balance VS household size\", x = 'household size', y = 'Total income, expenses and balance') +\n  scale_x_continuous(breaks = seq(0, 3, by = 1)) +\n  theme(plot.title = element_text(hjust = 0.1, size = 10, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        plot.caption = element_text(face = \"italic\", size = 10),\n        panel.grid.major.y = element_line(linewidth = 0.25, color = \"#bebebe\",linetype = 'dashed'),\n        panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_line(linewidth = 0.25, linetype = 'dashed', colour = '#bebebe'),\n        axis.text.x = element_text(face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5 ,face = \"bold\"))\n\nline_p1\n\n\n\n\n\n\n\n\nAn interactive box plot is used to better visualize the expenses of different age groups. A new “age_groups” column was added with 10 years’ interval.\nFrom the box plot, observed that:\n\nAge group “<20” has the highest average expense across all categories.\nAge group “21-30” has the lowest average expense across all categories.\nThe participant with the maximum expense (32.6k) is from 31-40 group.\n\n\n\nShow Code\n# create age_groups with labels\nmerged$age_groups <- cut(merged$age, \n                  breaks = c(10, 20, 30, 40, 50, 60), \n                  labels = c(\"<20\",\"21-30\", \"31-40\", \"41-50\", \"51-60\"))\n\n#income box plot\nt <- list(\n  family = \"Garamond\",\n  size = 19,\n  face = \"bold\")\n\nt1 <- list(\n  family = \"Garamond\",\n  size = 15,\n  face = \"bold\")\n\nbox <- plot_ly(\n  data = merged,\n  y = ~expenses_abs,\n  type = \"box\",\n  color = ~age_groups,\n  showlegend = FALSE,\n  boxmean = TRUE\n) %>% \n  layout(title= list(text = \"Box plot of total expenses in thousands by age group\",font = t1),\n         xaxis = list(title = list(text ='Age Group', font = t1)),\n         yaxis = list(title = list(text ='Total expenses in thousands', font = t1)))\n\nbox\n\n\n\n\n\n\n\n\n\nTo further understand the spending behaviors of each age group, a stacked bar chart is used to visualize the proportion of the average expenses (i.e. education, food, recreation and shelter).\nHowever from the stacked bar chart, there is not much spending behavior difference observed across the five age groups. The biggest proportion is always shelter, followed by recreation, food, and lastly education. The proportion for recreation and food is comparable, while education only contributes a small portion to total expense.\n\n\nShow Code\n#calculate avg of each expense category by age group, then change the table to long format\nmerged_aggregated <- merged %>%\n  group_by(age_groups) %>%\n    summarise(avg_education = mean(Education),\n              avg_food = mean(Food),\n              avg_recreation = mean(Recreation),\n              avg_shelter = mean(Shelter)) %>%\n  ungroup() %>% \n  mutate(across(c(avg_education, avg_food, avg_recreation, avg_shelter), abs))%>% \n  pivot_longer(cols = c(avg_education, avg_food, avg_recreation, avg_shelter), names_to = \"type\", values_to = \"value\")\n\n\n#plot the stacked bar chart\nbar <- ggplot(merged_aggregated, \n                aes(age_groups, value, fill = type)) + \n  geom_bar(stat=\"identity\") +\n  scale_fill_manual(values=c(\"#6666FF\", \"#99FFCC\", \"#FF99CC\",\"#FFCC99\"))+\n\n  labs(title = \"Proportion of Flat types by Planning area in Singapore\", x = \"Planning Area\", y = \"Count\", fill = \"Flat Type\") +\n  \n  theme_minimal() +\n  \n  theme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.4, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        axis.text = element_text(size = 8, face = \"bold\"),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\")) \n\nggplotly(bar)\n\n\n\n\n\n\n\n\n\nAfter visualizing expenses VS age group, I am also interested in the expense patterns with education level and interest group.\nIn this section, a treemap is used for a quick overall glimpse of expenses across different education levels and interest groups. Graduate and bachelors are having higher expenses than college or lower education level. Interest group B/F has relatively high proportion across all education levels.\n\n\nShow Code\n#calculate average expenses for different education level and interest groups\nmerged_aggr_tree <- merged %>%\n  group_by(educationLevel,interestGroup) %>%\n    summarise(avg_expenses = mean(expenses_abs)) %>%\n  ungroup()\n\n#plot treemap with size and color both representing expenses\ntreemap_area <- treemap (merged_aggr_tree,\n        index= c(\"educationLevel\",\"interestGroup\"),\n        vSize= \"avg_expenses\",\n        vColor = \"avg_expenses\",\n        type=\"value\",\n        palette = \"RdYlGn\",\n        border.col = c(\"black\", \"white\"),\n        title=\"expenses by educationLevel and interest group\",\n        title.legend = \"Average Expenses\"\n        )\n\n\n\n\n\n\n\n\nHypothetical Outcome Plot (HOP) are used to visualize the uncertainty of wage for different education levels.\nFrom the plot below, we can see that most of the time, bachelors and graduates can earn more than low or high school/college education level.\n\n\nShow Code\n#Wage VS education level HOP\nhop <- ggplot(data = merged, \n   (aes(x = educationLevel, \n        y = Wage))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                         group = educationLevel), \n          height = 0.6, \n          color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\nanim_save('hop_animation.gif',hop)\nhop\n\n\n\n\n\n\n\n\nScatter plot is used to investigate which category among the 6 has good correlation with joviality.\nThere is no good correlation between joviality and education, food or shelter. While recreation shows positive correlation with joviality, the more the participants spend on recreation, the happier they are. Surprisingly wage and joviality are in negative correlation.\n\n\nShow Code\n# Define y as joviality\ny_var <- merged$joviality\n\n# Define x as the 6 categories (absolute value)\nx_vars <- merged[, c(\"Education\", \"Food\", \"Recreation\",\"RentAdjustment\",\"Shelter\",\"Wage\")] %>%\n  mutate(across(c(\"Education\", \"Food\", \"Recreation\",\"RentAdjustment\",\"Shelter\",\"Wage\"), abs))\n\n# Reshape the data to long format\ndf <- reshape2::melt(cbind.data.frame(x_vars, y_var), id.vars = \"y_var\")\n\n# Create the plot\n\nggplot(df,aes(x = value, y = y_var)) +\n  geom_point(size = 1) +\n  coord_cartesian(ylim=c(0, 1))+\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~ variable, scales = \"free_x\", ncol = 3) +\n  labs(x = NULL, y = \"joviality\") +\n  ggtitle(\"joviality correlation scatter plot\") +\n  theme(plot.margin = margin(1, 1, 1, 1, \"cm\"))\n\n\n\n\n\n\n\n\nSince recreation shows a relatively good correlation with joviality, I did below animation to know about how recreation expenses changing over time.\nThe distribution of recreation expenses are more or less constant from early 2022 to early 2023, and it is slowly shifting right which means people tend to spend more on recreation over time.\n\n\nShow Code\n#filter recreation data and group by category \nfin_aggr <- fin_data %>%\n  mutate(year_mth = as.Date(paste(year_mth,\"-01\", sep=\"\"))) %>%\n  mutate(amount = abs(amount))%>%\n  filter(category %in% c(\"Recreation\"))%>%\n  group_by(category)%>%\n ungroup()\n\n#density ridge plot animation over time\ngg <- ggplot(data = fin_aggr, aes(x = amount, y = category, fill = after_stat(density))) +\n  \n  geom_density_ridges_gradient(scale = 5, rel_min_height = 0.01, height = 5, width = 6) +\n  \n  theme_minimal() +\n    \n  labs(title = 'Recreation expenses {frame_time} ') +\n  transition_time(year_mth) +\n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  axis.title.x = element_text(size = 10, hjust = 1),\n  axis.title.y = element_text(size = 10, angle = 360),\n  axis.text = element_text(size = 8)) +\n  scale_fill_viridis(name = \"amount\", option = \"D\") +\n  ease_aes('linear')\n\ngg"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex3.html",
    "href": "Take-home_EX/Take-home_Ex3.html",
    "title": "Take-home_Ex3",
    "section": "",
    "text": "With reference to Mini-Challenge 3 of VAST Challenge 2023 and by using appropriate static and interactive statistical graphics methods, you are required to help FishEye identify companies that may be engaged in illegal fishing. (website: https://vast-challenge.github.io/2023/MC3.html)\nQuestion chosen: Develop a visual analytics process to find similar businesses and group them. This analysis should focus on a business’s most important features and present those features clearly to the user.\n\n\n\n\nload packages and dataset\n\n\npacman::p_load(jsonlite, tidygraph, ggraph, \n               visNetwork, graphlayouts, ggforce, \n               skimr, tidytext,tidyverse,topicmodels,tm,plotly,ggstatsplot,rstantools,PMCMRplus)\n\n\nmc3_data <- fromJSON(\"data/MC3.json\")\n\n\nextract edges from JSON\n\n\nmc3_edges <- as_tibble(mc3_data$links) %>% \n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  ungroup()\n\n\nextract nodes from JSON\n\n\nmc3_nodes <- as_tibble(mc3_data$nodes) %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n  select(id, country, type, revenue_omu, product_services)\n\n\nDisplay the proportion of mc3_edges types (Beneficial owner and Company contacts)\n\n\n\nShow Code\n# Calculate the count of X by Category\nedge_type_summary <- mc3_edges %>%\n  group_by(type) %>%\n  summarise(Count = n())%>%\n  ungroup()\n\n# Create pie chart using ggplot\nchart <- ggplot(edge_type_summary, aes(x = \"\", y = Count, fill = type)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\")) +\n  geom_text(aes(label = paste0(round(Count/sum(Count)*100,2), \"%\")), position = position_stack(vjust = 0.5))\n\nchart\n\n\n\n\n\n\nRecoding “character(0)” to “others” in product_services field for all nodes.\n\n\n#recode nodes with product_services is character(0)\nmc3_nodes$product_services <- ifelse(mc3_nodes$product_services == \"character(0)\", \"others\", mc3_nodes$product_services)\n\n\nDisplay the proportion of mc3_nodes types (Beneficial owner/Company contacts/Company)\n\n\n\nShow Code\n# Calculate the count of X by Category\nnode_type_summary <- mc3_nodes %>%\n  group_by(type) %>%\n  summarise(Count = n()) %>%\n  ungroup()\n\n# Create pie chart using ggplot\nchart2 <- ggplot(node_type_summary, aes(x = \"\", y = Count, fill = type)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\",\"lightgrey\")) +\n  geom_text(aes(label = paste0(round(Count/sum(Count)*100,2), \"%\")), position = position_stack(vjust = 0.5))\n\nchart2\n\n\n\n\n\n\n\n\n\nPerform basic text analysis preprocessing (change to lowercase, remove punctuation, remove numbers, remove stopwords) and create a document-term matrix after that. Nodes with “others” and “Unknown” product services are excluded from this text analysis section.\n\n\n# Create a corpus from product_services\nmc3_nodes <- mc3_nodes %>%\n  filter(!product_services%in% c(\"others\", \"Unknown\"))\nprint(paste(length(mc3_nodes$id),\" nodes left in the dataset.\"))\n\n[1] \"4018  nodes left in the dataset.\"\n\n#create a corpus object\ncorpus <- Corpus(VectorSource(mc3_nodes$product_services))\n\n# Perform basic preprocessing (lowercase, remove punctuation, remove numbers, remove stopwords)\ncorpus <- tm_map(corpus, removeNumbers)\ncorpus <- tm_map(corpus, content_transformer(tolower))\ncorpus <- tm_map(corpus, removePunctuation)\ncorpus <- tm_map(corpus, removeNumbers)\ncorpus <- tm_map(corpus, removeWords, stopwords(\"english\"))\n\n# Create a document-term matrix\ndtm <- DocumentTermMatrix(corpus)\n\n\nLDA topic modelling (limited to 5 topics)\n\n\n# Fit the LDA model\nlda_model <- LDA(dtm, control=list(seed=1), k = 5) \n\n\nDisplay the top 7 terms for each of the topic\n\n\n\nShow Code\n# Retrieve the top 7 terms for each topic\ntopics <- terms(lda_model, 7)  \n\n# Display the topics and associated terms\nfor (i in 1:5) {\n  cat(\"Topic\", i, \":\", paste(topics[,i], collapse = \", \"), \"\\n\")\n}\n\n\nTopic 1 : services, freight, transportation, logistics, source, freelance, researcher \nTopic 2 : fish, salmon, products, frozen, tuna, shrimp, squid \nTopic 3 : products, shoes, footwear, chemicals, oil, apparel, well \nTopic 4 : products, equipment, materials, systems, parts, machines, steel \nTopic 5 : products, seafood, fish, food, frozen, fresh, related \n\n\nFrom the top terms of each topic, we can easily summarize the respective business feature for the groups as below:\nTopic 1: transportation and logistics\nTopic 2: fish and other seafood\nTopic 3: chemicals and accessories\nTopic 4: equipment\nTopic 5: food products\n\nMap the topics back to the nodes table as their groups.\n\n\n\nShow Code\n#extract the probability for each topic\ndoc_topic_probs <- as.data.frame(topics(lda_model))\n\n# Map topics back to documents\nmapped_nodes <- cbind(mc3_nodes, doc_topic_probs) %>%\n  rename_with(.col=6, ~\"topic\")%>%\n  mutate(topic = as.character(topic))\n\n#recode topic names\nmapped_nodes$topic_name <- case_when(\n  mapped_nodes$topic == 1 ~ \"transportation and logistics\",\n  mapped_nodes$topic == 2 ~ \"fish and other seafood\",\n  mapped_nodes$topic == 3 ~ \"chemicals and accessories\",\n  mapped_nodes$topic == 4 ~ \"equipment\",\n  TRUE ~ \"food products\"\n)\n\n\n\nVisualize the business group (topics) distribution for each node type.\n\nThe bar chart below shows the topic distribution for each type of nodes.\n\nFor beneficial owner, none of them are grouped under “chemicals and accessories”. Majority of them are doing fish and seafood related business.\nCompanies that are grouped under equipment and food products are more than the other three businesses.\nFor company contacts, there is only one record left. As company contacts should represent his company, its business feature is not meaningful in this context.\n\n\n\nShow Code\n# Calculate the count of nodes by type\ntopic_dist <- mapped_nodes %>%\n  group_by(type, topic_name) %>%\n  summarise(Count = n()) %>%\n  ungroup()\n\n# Create the bar chart\np <- ggplot(topic_dist, aes(x = topic_name, y = Count, fill=type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~ type, scales = \"free_y\") +\n  xlab(\"\") +\n  theme(axis.text.x = element_text(angle = 60, hjust = 1))\n\nggplotly(p)\n\n\n\n\n\n\n\nExplore the average revenue for each business group.\n\nEquipment business group has the highest mean revenue, followed by fish and other seafood products.\n\n\nShow Code\nggbetweenstats(\n  data = mapped_nodes,\n  x = topic_name,\n  y = revenue_omu,\n  xlab = \"Business Group\",\n  ylab = \"Revenue\",\n  type = \"np\", #conduct non-parametric test\n  conf.level = 0.95,\n  mean.ci = TRUE,\n  package = \"ggsci\",\n  palette = \"default_jco\"\n) \n\n\n\n\n\n\n\n\n\nFor a quick overview, build the network model with tidygraph.\n\n\n\nShow Code\n#create an updated unique node list from the edge list\nid1 <- mc3_edges %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- mc3_edges %>%\n  select(target) %>%\n  rename(id = target)\nmc3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n#build graph object and calculate centrality measures\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n#plot the network only for nodes with betweenness >=100000\nmc3_graph %>%\n  filter(betweenness_centrality >= 100000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()\n\n\n\n\n\n\nThe plot is very dense, thus we want to zoom in to a smaller group for further analysis.\n\nA person who owns many companies are more suspicious than others. The next step is to detect such anomalies by focusing on the beneficial owners who have >= 5 companies.\n\n\nShow Code\n#filter out beneficial owner only, and summarize their number of company ownership\nowner_freq <- mc3_edges %>% \n  filter(type == \"Beneficial Owner\") %>%\n  group_by(target) %>%\n    summarise(companies_owned=n()) %>%\n  arrange(desc(companies_owned)) %>%\n  filter(companies_owned >1) %>%\n  ungroup()\n\n#bar plot for company ownership count \nowner_freq_gg <- ggplot(data = owner_freq,\n       aes(x = companies_owned)) +\n  geom_bar()+\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"num of companies ownered\",\n      y = \"Frequency\",\n      title = \"company ownership distribution\")\n\nggplotly(owner_freq_gg)\n\n\n\n\n\n\nEdges for targets with exactly one ownership have already been eliminated (they are less suspicious too). Based on the distribution plot, I will set the threshold at 5 (inclusive), in order to focus on the tail for further analysis.\nSuspicious target person who owns more than or equal to 5 companies:\n\n\nShow Code\nowner_freq_reduced  <- owner_freq %>% \n  filter(companies_owned >= 5) \n\nDT::datatable(owner_freq_reduced)\n\n\n\n\n\n\n\n\nNetwork visualization of beneficial owners with more than 5 companies. Node size represents betweenness centrality, color represents the business group (grey means its product_services is not available).\n\n\n\nShow Code\n#set random seed\nset.seed(12)\n\n#filter out edges with the suspicious beneficial owner only\nsub_edge <- mc3_edges %>% \n  filter(target %in% c(owner_freq_reduced$target)) \n\n#create an updated unique node list from the edge list\nid1 <- sub_edge %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- sub_edge %>%\n  select(target) %>%\n  rename(id = target)\nsub_node <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(mapped_nodes,by = \"id\",unmatched = \"drop\")%>%\n  distinct(id,.keep_all = TRUE)\n\n#build graph object and calculate centrality measures\nmc3_graph <- tbl_graph(nodes = sub_node,\n                       edges = sub_edge,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness())\n\n#plot the network \nmc3_graph %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    color = topic_name,\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()\n\n\n\n\n\n\nNow let us use VisNetwork to make it an interactive plot (company is marked in star).\n\n\n\nShow Code\n#plot visnetwork graph - first need to change column name\n sub_edge <- sub_edge %>%\n    rename(from = source) %>%\n    rename(to = target)\n\n#set random seed\nset.seed(12)\n\n#store betweenness values\nbetweenness_values <- mc3_graph %>%\n  pull(betweenness_centrality)\n\n#store attributes with respective column name that is readable by visnetwork\nsub_node$group <- sub_node$topic_name\nsub_node$value <- betweenness_values\nsub_node$shape <- ifelse(sub_node$type==\"Company\",\"star\",\"dot\")\nsub_edge$value <- sub_edge$weights\n\nvisNetwork(sub_node,sub_edge) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,nodesIdSelection = TRUE,selectedBy = \"topic_name\") %>%\n  visGroups(groupname = \"food products\", color = \"orange\") %>%\n  visGroups(groupname = \"fish and other seafood\", color = \"red\") %>%\n  visGroups(groupname = \"transportation and logistics\", color =  \"lightgreen\") %>%\n  visGroups(groupname = \"equipment\", color =\"purple\") %>%\n  visGroups(groupname = \"chemicals and accessories\", color = \"yellow\") %>%\n  visLegend(position = \"right\")\n\n\n\n\n\n\n\nBy applying LDA topic modelling on the product service attribute, I successfully identified the most important business feature for each node and grouped them based on similar business (5 groups). (The nodes with unavailable product_service data are in blue.) From the network, we can observe that usually there are more than one types of business within each small cluster, which is expected because a business chain usually involves more than one type of products/services.\nFishEye has determined that companies with anomalous structures are far more likely to be involved in IUU (or other “fishy” business). From the network graphs above, we can clearly observe a big cluster which is suspicious. Each beneficial owner in this cluster owns >=5 companies. This cluster includes several high betweenness nodes as well. Beneficial owner “Jessica Brown” is the essential linkage in this cluster. Therefore her 1-hop neighbouring companies are likely to be involved in IUU fishing too, such as: - BlueTide GmbH & Co. KG - Mar del Oeste - - West Fish GmbH Transport\nBesides, there is another company from this cluster named “Nagaland Sea Catch Ltd. Liability Co Logistics” also has high betweenness, as it links two major beneficial owner David Thomas and Mary Williams. This company might also involve in IUU fishing."
  },
  {
    "objectID": "In-class_EX/In-class_Ex08/geospatial/MPSZ-2019.html",
    "href": "In-class_EX/In-class_Ex08/geospatial/MPSZ-2019.html",
    "title": "My VAA Journey",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  }
]